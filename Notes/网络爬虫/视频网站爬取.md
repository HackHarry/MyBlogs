## 网站视频爬取

昨晚写了个爬虫，爬取了一部电影《小丑》，想着公众号好久没更新了，记录一下爬虫的经过。然后我好像是第一次在公众号记录爬虫，就稍微写的详细一些吧，顺便整理一下原理之类的东西。

#### 网页分析

我们要爬取的网页是`https://dm.xbdm.net/dm/30416.html`

视频网站基本不可能是静态网站的，不然加载视频会非常耗时，所以盲猜通过加载很多小视频然后拼接播放。因此，直接打开chrome的开发者工具(F12)，利用Ajax特殊的请求类型XHR，尝试捕获Ajax请求。

> Ajax，全称为Asynchronous Javascript and XML，即异步的Javascript和XML，是一项利用JavaScript在保证页面不被刷新、链接也不变的情况下与服务器交换数据并更新部分网页的技术。

![img](https://mmbiz.qpic.cn/mmbiz_jpg/NKpIj6RCKSJRmSdMZjibPY7ic4c1pa6t5KUSSib7x9WPDBIGn9yewkOhHib7oZt3QiagbkxljF87qAic0DicUGh4Uhpiaw/640?wx_fmt=jpeg&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

在开发者工具的上方切换到network选项卡，过滤器选择XHR，筛选出所有type类型为XHR的请求，可以看到目前捕获了一些Ajax请求。其中film_00000.ts之类的文件就是视频缓存文件了，尝试直接下载下来，发现能够直接看，命名也很有规范，可以直接用循环下载。虽然可以直接写爬虫了，但是我们再来关注一下index.m3u8文件。

> m3u8文件其实是HTTP Live Streaming（缩写为 HLS）协议的部分内容，而HLS是一个由苹果公司提出的基于HTTP的流媒体网络传输协议。
> HLS的工作原理是把整个流分成一个个小的基于HTTP的文件来下载，每次只下载一些。当媒体流正在播放时，客户端可以选择从许多不同的备用源中以不同的速率下载同样的资源，允许流媒体会话适应不同的数据速率。在开始一个流媒体会话时，客户端会下载一个包含元数据的extended M3U(m3u8) playlist文件，用于寻找可用的媒体流。

以上是百度来的对于m3u8的介绍。实际上，m3u8相当于一个播放列表，里面存放着所有视频。一般来说，视频网站为了防止视频被盗，会设置混淆加密，并在播放的同时更新m3u8列表。但查看m3u8文件之后，我们可以看到这个网站没有设置加密，因此可以直接下载而不需要解密了。

```
#EXTM3U
#EXT-X-VERSION:3
#EXT-X-ALLOW-CACHE:YES
#EXT-X-TARGETDURATION:7
#EXT-X-MEDIA-SEQUENCE:0
#EXTINF:5.440000,
/hls/20191217/7120554b4004b3956c5baac0aac596cb/1576573583/film_00000.ts
#EXTINF:4.920000,
/hls/20191217/7120554b4004b3956c5baac0aac596cb/1576573583/film_00001.ts
#EXTINF:5.320000,
/hls/20191217/7120554b4004b3956c5baac0aac596cb/1576573583/film_00002.ts
#EXTINF:6.000000,
/hls/20191217/7120554b4004b3956c5baac0aac596cb/1576573583/film_00003.ts
#EXTINF:4.000000,
/hls/20191217/7120554b4004b3956c5baac0aac596cb/1576573583/film_00004.ts
#EXTINF:6.000000,
/hls/20191217/7120554b4004b3956c5baac0aac596cb/1576573583/film_00005.ts
...
```

再展示一下有加密的m3u8文件的部分内容。可以看到，下方的列表里有很长的后缀，其中有一项encrypt参数，就是会不停变更的加密key。如果要爬取这样的视频，就会麻烦很多。

```
#EXTM3U
#EXT-X-VERSION:3
#EXT-X-TARGETDURATION:14
#EXTINF:11.580,
5100069772_5005948585_55.mp4_0-0.ts?msisdn=40e179556659c597a96d2881be861ee4&mdspid=&spid=800033&netType=0&sid=5500091432&pid=2028597139&timestamp=20191221204950&Channel_ID=0116_25000000-99000-100300010010001&ProgramID=624311489&ParentNodeID=-99&assertID=5500091432&client_ip=117.147.10.110&SecurityKey=20191221204950&promotionId=&mvid=5100069772&mcid=1000&mpid=130000015172&playurlVersion=SJ-H1-0.0.3&userid=&jmhm=&videocodec=h264&encrypt=b9e1b133d5f4c9874760349e96691a1c&hls_type=2&HlsSubType=2&HlsProfileId=0&mtv_session=7a1ef51d7cec8f6cf972afc1a4f855b3
#EXTINF:10.000,
5100069772_5005948585_55.mp4_0-1.ts?msisdn=40e179556659c597a96d2881be861ee4&mdspid=&spid=800033&netType=0&sid=5500091432&pid=2028597139&timestamp=20191221204950&Channel_ID=0116_25000000-99000-100300010010001&ProgramID=624311489&ParentNodeID=-99&assertID=5500091432&client_ip=117.147.10.110&SecurityKey=20191221204950&promotionId=&mvid=5100069772&mcid=1000&mpid=130000015172&playurlVersion=SJ-H1-0.0.3&userid=&jmhm=&videocodec=h264&encrypt=6cefa87989771a710953990913a99303&hls_type=2&HlsSubType=2&HlsProfileId=0&mtv_session=7a1ef51d7cec8f6cf972afc1a4f855b3
...
```

#### 爬虫代码

爬虫的逻辑很简单，因为所有的ts文件都是类似的命名方式，只需要写个循环将所有的ts文件下载下来即可。因为文件也不多，也就没必要写多线程了，单线程跑个几分钟就下完了，一盘三国杀的时间都不到。

```python
# 因为实际上我是用jupyter写的python代码，可以断点断续，
# 所以我没有写一些异常判断和处理，实际上这样写并不好。
import requests
import time

def download(url):
    headers = {
            'User-Agent': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/55.0.2883.87 Safari/537.36',
            'Accept-Encoding': 'gzip, deflate, sdch',
            'Accept-Language': 'zh-CN,z;q=0.8'
        }
    response = requests.get(url, headers=headers)
    filename = './videos/'+url[-7:]
    with open(filename, "wb") as fp:
        fp.write(response.content)

if __name__ == '__main__':
    url = 'https://ll1.7639616.com/hls/20191217/7120554b4004b3956c5baac0aac596cb/1576573583/film_'
    for i in range(0, 1462):
        # zfill()的用处是填充，比如0填充成00000
        download(url + str(i).zfill(5) + '.ts')
        print(i)
        time.sleep(0.2)
    print('---------------------------------------------------')
```

#### ts文件合并

下载完成后，我们就获得一个文件夹的ts文件，当然我们不能一个个点过去看，当然是要合并起来的。这里我直接用命令行的命令进行合并，我写了个bat文件，功能是将所有的ts文件合并为video.mp4。之所以能这么做，是因为视频文件都是以二进制形式存在的。

这里有一个注意点，Windows是按照字符来识别顺序的，而非数字，所以在python保存文件时需要命名为0000、0001这种形式。如果以0、1、2这种方式命名，最后的合并会出现问题，系统会以1、10这样字符串大小顺序来合并。

```
cd ./videos
copy /b *.ts video.mp4
move video.mp4 ../
pause
```

当命令行执行完成后，你就获得一个完整的视频了^_^！


 